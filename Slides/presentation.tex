\documentclass{beamer}

\usepackage[utf8]{inputenc}


%Information to be included in the title page:
\title{Particle Filtering}
\author{Alex Pan and Alec Kosik}
\institute{Reed College}
\date{2016}



\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Hidden Markov Models (HMM)}
{\large
\begin{equation*}
X_1 \sim \mu (x_1) \textnormal{ and } X_n|(X_{n-1}=x_{n-1}) \sim f(x_n|x_{n-1})
\end{equation*}
\begin{equation*}
Y_n|(X_n = x_n) \sim g(y_n|x_n)
\end{equation*}
}
\end{frame}

\begin{frame}
\frametitle{Problem Setup}
{\Large Goal:}
\begin{equation*}
p(x_{n}|y_{1:n})
\end{equation*}
{\Large Have:} \\[.5cm]
{\large From Markov Property:}
\begin{gather*}
p(x_{1:n}) = \mu(x_1)\prod_{i=2}^{n} f(x_i|x_{i-1})\\
p(y_{1:n}|x_{1:n}) = \prod_{i=1}^{n} g(y_i|x_i)
\end{gather*}
\end{frame}

\begin{frame}
\frametitle{Deriving our Goal $p(x_n|y_{1:n})$ from our Markovian Assumptions}
\begin{align*}
p(x_{1:n}|y_{1:n}) &= \frac{p(x_{1:n}, y_{1:n})}{p(y_{1:n})} \\
&= \frac{p(y_{1:n}|x_{1:n})p(x_{1:n})}{p(y_{1:n})}
\end{align*}
{\large Notice that $p(x_n|y_{1:n})$ is just a marginal of the above equation.}
\begin{equation*}
p(x_n|y_{1:n}) = \int \cdots \int p(x_{1:n}|y_{1:n}) \,dx_{1:n-1}
\end{equation*}
{\large Not always integrable e.g. non-linear, non-gaussian distributions}
\end{frame}

\begin{frame}
\frametitle{\dots At least we still have this \dots}
\begin{align*}
p(x_{1:n}|y_{1:n}) &= \frac{p(x_{1:n}, y_{1:n})}{p(y_{1:n})} \\
&= \frac{p(y_{1:n}|x_{1:n})p(x_{1:n})}{p(y_{1:n})} \\
&= \frac{(\prod_{i=1}^{n} g(y_i|x_i))(\mu(x_1)\prod_{i=2}^{n} f(x_i|x_{i-1}))}{p(y_{1:n})} \\
&= p(x_{1:n-1}|y_{1:n-1})\frac{g(y_n|x_n))f(x_n|x_{n-1})}{p(y_n|y_{1:n-1})} \\
&= \underbrace{p(x_{1:n-1}|y_{1:n-1})}_{\text{recursion}} \underbrace{\frac{g(y_n|x_n)}{p(y_n|y_{1:n-1})}}_{\text{update/weight}} \underbrace{f(x_n|x_{n-1})}_{\text{transition probability}}
\end{align*}
\end{frame}

\begin{frame}
\frametitle{Sequential Importance Sampling (SIS)}
\begin{enumerate}
\item \textit{Initialization:}
\item[] For $i=1,\dots N$:
\begin{itemize}
\item[] Sample $x_0^{(i)} \sim \mu(x_0)$ 
\item[] Assign weights $\widetilde{w}_0^{(i)} = \alpha_n(x_1)$
\end{itemize}
\item \textit{Importance Sampling:}
\item[] For $t=1,\dots,T$:
\begin{itemize}
\item[] Sample $x_t^{(i)} \sim f(x_t|x_{t-1}^{i})$
\item[] Assign weights $\widetilde{w}_t^{(i)} = w_{t-1}(x_{1:n-1})\alpha(x_{1:n})=w_1(x_1)\prod_{k=2}^{n}\alpha_k(x_{1:k})$
\end{itemize}
\item Return $\{x_T^{(i)},w_T^{(i)}\}_{i=1}^N$
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Sequential Importance Resampling (SIR)}
\begin{enumerate}
\item \textit{Initialization:}
\item[] For $i=1,\dots N$:
\begin{itemize}
\item[] Sample $x_0^{(i)} \sim \mu(x_0)$ 
\item[] Assign weights $\widetilde{w}_0^{(i)} = g(y_0|x_0^{(i)})$
\item[] Normalize weights $w_0^{(i)} = \frac{\widetilde{w}_0^{(i)}}{\sum_{i=1}^{n} \widetilde{w}_0^{(i)}}$
\end{itemize}
\item \textit{Importance Sampling:}
\item[] For $t=1,\dots,T$:
\begin{itemize}
\item[] Sample $x_t^{(i)} \sim f(x_t|\widetilde{x}_{t-1}^{i})$
\item[] Assign weights $\widetilde{w}_t^{(i)} = g(y_t|x_t^{(i)})$
\item[] Normalize weights $w_t^{(i)} = \frac{\widetilde{w}_t^{(i)}}{\sum_{i=1}^{n} \widetilde{w}_t^{(i)}}$
\item[] Resample $\widetilde{x}_t^{(i)}$ from $x_t^{(i)}$ according to the weight distribution.
\end{itemize}
\item Return $\{x_T^{(i)},w_T^{(i)}\}_{i=1}^N$
\end{enumerate}
\end{frame}


\end{document}
